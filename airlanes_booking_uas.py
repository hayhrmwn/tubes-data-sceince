# -*- coding: utf-8 -*-
"""airlanes Booking UAS.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13y1PpGhq0IyKw7EsWCHD5W99UhL8u-LE

Muhammad Nur Maajid_1103228145

---


Mohammad Jody Hermawan_1103228241

---


Khairi Hibatullah Ridho_1103228240

Struktur Dataset
1. num_passengers = number of passengers travelling
2. sales_channel = sales channel booking was made on
3. trip_type = trip Type (Round Trip, One Way, Circle Trip)
4. purchase_lead = number of days between travel date and booking date
5. length_of_stay = number of days spent at destination
6. flight_hour = hour of flight departure
7. flight_day = day of week of flight departure
8. route = origin -> destination flight route
9. booking_origin = country from where booking was made
10. wants_extra_baggage = if the customer wanted extra baggage in the booking
11. wants_preferred_seat = if the customer wanted a preferred seat in the booking
12. wants_in_flight_meals = if the customer wanted in-flight meals in the booking
13. flight_duration = total duration of flight (in hours)
14. booking_complete = flag indicating if the customer completed the booking

#Exploring Data
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import plotly.express as px
import seaborn as sns
import plotly.graph_objects as go
from bokeh.models import ColumnDataSource
from bokeh.plotting import figure, show
from bokeh.transform import dodge
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split, cross_val_score
from google.colab import drive

drive.mount('/content/drive')
data_path = '/content/drive/MyDrive/Dataset/customer_booking.csv'
df = pd.read_csv(data_path, encoding='latin1')

data_path = '/content/customer_booking.csv'
df = pd.read_csv(data_path, encoding='latin1')

"""1. Exploring Data."""

df.head(10)

df.tail(10)

"""2. Checking the data types."""

df.info()

"""The Dataset contain mulitple objects, int64 and float64 data types."""

df.describe()

"""3. Checking For Null Values in the dataset."""

df.isnull().sum()

df.nunique()

"""4. Checking the unique values in columns obtain object64 data types"""

df['sales_channel'].unique()

df['trip_type'].unique()

df['flight_day'].unique()

df['booking_origin'].unique()

"""5. Hence there is a spelling mistake in booking origin Replacing it with correct spellings."""

df['booking_origin'] = df['booking_origin'].replace('R\x82union','Reunion')

df['booking_origin'].unique()

"""6. Checking data of specific Value in booking_origin column for '(not set)'"""

target_value = '(not set)'
filtered_df = df[df['booking_origin'] ==target_value]
filtered_df

df['flight_duration'].unique()

df['route'].unique()

df.select_dtypes(include=['object']).head(10)

df2 = df.select_dtypes(include=['number']).head(10)
df2

df.drop_duplicates()

sns.scatterplot(df)

"""7. Checking Co-relation of the variables."""

corr_matrix = df2.corr()
corr_matrix

sns.scatterplot(df, x= 'purchase_lead', y='flight_hour',hue='sales_channel')

"""#wants extra baggage prediction"""

df = pd.get_dummies(df, columns=["sales_channel", "trip_type", "flight_day", "route", "booking_origin"], drop_first= True)

y = df["wants_extra_baggage"]
x = df.drop("wants_extra_baggage", axis= 1)


x_train, x_test, y_train, y_test = train_test_split(x, y, train_size= 0.85, random_state= 42)

"""RandomForestClassifier"""

rf = RandomForestClassifier()

model = rf.fit(x_train, y_train)
score = model.score(x_test, y_test)
print("Model Skor: ", score)

cross_val = cross_val_score(model, x, y, cv = 4)

cross_val

cross_val.mean()

"""XGBOOST"""

import xgboost as xgb
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import accuracy_score

# Initialize and train the XGBoost model
xgb_model = xgb.XGBClassifier(eval_metric='logloss', use_label_encoder=False)

xgb_model.fit(x_train, y_train)

y_pred = xgb_model.predict(x_test)
score = accuracy_score(y_test, y_pred)
print("XGBoost Model Score: ", score)

# Cross-validation
cross_val = cross_val_score(xgb_model, x, y, cv=4)
print("Cross-validation scores: ", cross_val)
print("Cross-validation mean: ", cross_val.mean())

"""LightGBM"""

import lightgbm as lgb

# Initialize and train the LightGBM model
lgb_model = lgb.LGBMClassifier()

lgb_model.fit(x_train, y_train)

# Evaluate the model
y_pred = lgb_model.predict(x_test)
score = accuracy_score(y_test, y_pred)
print("LightGBM Model Score: ", score)

# Cross-validation
cross_val = cross_val_score(lgb_model, x, y, cv=4)
print("Cross-validation scores: ", cross_val)
print("Cross-validation mean: ", cross_val.mean())

"""AdaBoost"""

from sklearn.ensemble import AdaBoostClassifier

ada_model = AdaBoostClassifier(n_estimators=100, random_state=42)

ada_model.fit(x_train, y_train)

y_pred = ada_model.predict(x_test)
score = accuracy_score(y_test, y_pred)
print("AdaBoost Model Score: ", score)

cross_val = cross_val_score(ada_model, x, y, cv=4)
print("Cross-validation scores: ", cross_val)
print("Cross-validation mean: ", cross_val.mean())

"""SVM

"""

from sklearn.svm import SVC
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import make_pipeline

svm_model = make_pipeline(StandardScaler(), SVC(kernel='linear', random_state=42))

svm_model.fit(x_train, y_train)

y_pred = svm_model.predict(x_test)
score = accuracy_score(y_test, y_pred)
print("SVM Model Score: ", score)

"""#Model Save"""

!pip install joblib

import joblib
from google.colab import files
models = {
    'random_forest': rf,
    'xgboost': xgb_model,
    'lightgbm': lgb_model,
    'adaboost': ada_model,
    'svm': svm_model
}

# Menyimpan dictionary model ke file .sav
joblib_file = "models.sav"
joblib.dump(models, joblib_file)

# Mengunduh file model ke komputer lokal
files.download(joblib_file)

import joblib

# Menyimpan setiap model ke file pickle terpisah
joblib.dump(rf, "rf_model.pkl")
joblib.dump(xgb_model, "xgb_model.pkl")
joblib.dump(lgb_model, "lgb_model.pkl")
joblib.dump(ada_model, "ada_model.pkl")
joblib.dump(svm_model, "svm_model.pkl")